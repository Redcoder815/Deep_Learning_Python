{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_Python/blob/main/L2Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Model (Forward Pass): The forward function calculates the predicted output y_pred using the standard linear equation:\n",
        "\n",
        "y_pred = X @ W + b\n",
        "\n",
        "Where:\n",
        "\n",
        "X is your input feature matrix.\n",
        "W (weights) are the coefficients that determine the influence of each feature.\n",
        "b (bias) is the intercept term.\n",
        "2. Mean Squared Error (MSE) Loss: The mse_loss function measures how well your model's predictions y_pred match the actual true values y. It calculates the average of the squared differences between them:\n",
        "\n",
        "MSE = (1/N) * sum((y_pred - y_true)^2)\n",
        "\n",
        "This is a common metric to quantify the error, and the goal of training is to minimize this error.\n",
        "\n",
        "3. L2 Regularization Loss: The l2_loss function adds a penalty to the total loss based on the magnitude of the weights W. This helps prevent overfitting by discouraging the model from assigning very large values to the weights.\n",
        "\n",
        "L2_Loss = 0.5 * lam * sum(W^2)\n",
        "\n",
        "Where lam (lambda) is the regularization strength. A larger lam means a stronger penalty on the weights.\n",
        "\n",
        "4. Total Loss: The overall loss that the model tries to minimize is the sum of the MSE loss and the L2 regularization loss:\n",
        "\n",
        "Total_Loss = MSE_Loss + L2_Loss\n",
        "\n",
        "5. Gradient Calculation (compute_grads): This is the core of the optimization process. It calculates how much each parameter (W and b) needs to change to reduce the Total_Loss.\n",
        "\n",
        "Gradient of Loss wrt Predictions (dL_dy): First, it calculates how the MSE loss changes with respect to the predictions:\n",
        "\n",
        "dL_dy = (2/N) * (y_pred - y)\n",
        "\n",
        "Gradient of Loss wrt Weights (dW): Using the chain rule, it calculates the gradient for the weights. This includes the gradient from the MSE term and the gradient from the L2 regularization term:\n",
        "\n",
        "dW = X.T @ dL_dy + lam * W\n",
        "\n",
        "The lam * W term comes directly from the derivative of 0.5 * lam * sum(W^2) with respect to W.\n",
        "\n",
        "Gradient of Loss wrt Bias (db): Similarly, the gradient for the bias is calculated:\n",
        "\n",
        "db = sum(dL_dy)\n",
        "\n",
        "6. Gradient Descent Update: In each epoch (iteration), the W and b parameters are updated by moving a small step (lr, the learning rate) in the opposite direction of their respective gradients:\n",
        "\n",
        "W = W - lr * dW b = b - lr * db\n",
        "\n",
        "This iterative process gradually moves the W and b values towards the ones that minimize the Total_Loss function."
      ],
      "metadata": {
        "id": "KZS5iwHW6Qnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dL_dy (Gradient of Loss with respect to Predictions y_pred)\n",
        "This term represents how sensitive the Mean Squared Error (MSE) loss is to changes in your model's predictions (y_pred).\n",
        "\n",
        "The MSE loss function is defined as: L_MSE = (1/N) * Σ(y_pred - y_true)²\n",
        "\n",
        "To find dL_dy (which is ∂L_MSE / ∂y_pred), we differentiate L_MSE with respect to y_pred: dL_dy = ∂/∂y_pred [ (1/N) * Σ(y_pred - y_true)² ] dL_dy = (1/N) * Σ[ 2 * (y_pred - y_true) * ∂/∂y_pred (y_pred - y_true) ] dL_dy = (1/N) * Σ[ 2 * (y_pred - y_true) * 1 ] dL_dy = (2/N) * (y_pred - y_true)\n",
        "\n",
        "This dL_dy is then a vector where each element tells you how much the loss changes for a unit change in the corresponding prediction.\n",
        "\n",
        "2. dW (Gradient of Loss with respect to Weights W)\n",
        "The dW term represents how sensitive the total loss (MSE loss + L2 regularization loss) is to changes in your model's weights W.\n",
        "\n",
        "The total loss is: L_total = L_MSE + L_L2 So, dW = ∂L_total / ∂W = ∂L_MSE / ∂W + ∂L_L2 / ∂W\n",
        "\n",
        "Let's break it down:\n",
        "\n",
        "a) Contribution from MSE Loss (∂L_MSE / ∂W) We use the chain rule, knowing that y_pred = X @ W + b. ∂L_MSE / ∂W = (∂L_MSE / ∂y_pred) @ (∂y_pred / ∂W)\n",
        "\n",
        "We already found ∂L_MSE / ∂y_pred = dL_dy.\n",
        "For ∂y_pred / ∂W: y_pred = X @ W + b Differentiating this with respect to W (a matrix derivative), we get X.T.\n",
        "More formally, if y_pred_i = Σ_j X_ij W_j + b, then ∂y_pred_i / ∂W_k = X_ik. So, ∂y_pred / ∂W is X.T when dL_dy is a column vector.\n",
        "Therefore, ∂L_MSE / ∂W = X.T @ dL_dy\n",
        "\n",
        "b) Contribution from L2 Regularization Loss (∂L_L2 / ∂W)\n",
        "\n",
        "The L2 regularization loss is defined as: L_L2 = 0.5 * lam * Σ(W²) = 0.5 * lam * WᵀW (for vector W)\n",
        "\n",
        "To find ∂L_L2 / ∂W, we differentiate L_L2 with respect to W: ∂L_L2 / ∂W = ∂/∂W [ 0.5 * lam * Σ(W²) ] ∂L_L2 / ∂W = 0.5 * lam * Σ[ 2 * W * ∂W/∂W ] ∂L_L2 / ∂W = lam * W\n",
        "\n",
        "c) Combining them for dW dW = X.T @ dL_dy + lam * W\n",
        "\n",
        "This is exactly what you see in the compute_grads function.\n",
        "\n",
        "3. db (Gradient of Loss with respect to Bias b)\n",
        "The db term represents how sensitive the total loss is to changes in your model's bias b.\n",
        "\n",
        "Since the L2 regularization is only applied to weights W and not bias b, the db gradient only comes from the MSE loss.\n",
        "\n",
        "db = ∂L_total / ∂b = ∂L_MSE / ∂b\n",
        "\n",
        "Again, we use the chain rule: ∂L_MSE / ∂b = (∂L_MSE / ∂y_pred) @ (∂y_pred / ∂b)\n",
        "\n",
        "We know ∂L_MSE / ∂y_pred = dL_dy.\n",
        "For ∂y_pred / ∂b: y_pred = X @ W + b Differentiating y_pred with respect to b, we get a vector of ones (if b is a scalar that's broadcast across all y_pred). Essentially, a change in b affects each y_pred_i equally by 1.\n",
        "Therefore, ∂L_MSE / ∂b = Σ(dL_dy) (summing up the individual gradients dL_dy for each sample because the scalar b affects all samples equally).\n",
        "\n",
        "This is why in the compute_grads function, db = np.sum(dL_dy, axis=0).\n",
        "\n",
        "These gradients are then used in the gradient descent update step to adjust W and b in the direction that minimizes the total loss.\n",
        "\n"
      ],
      "metadata": {
        "id": "U4Z1yEDC6KOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "X = np.random.randn(100, 3)\n",
        "true_W = np.array([[2.0], [-3.0], [1.0]])\n",
        "y = X @ true_W + 0.5 * np.random.randn(100, 1)\n",
        "\n",
        "W = np.random.randn(3, 1)\n",
        "b = np.zeros((1,))\n",
        "\n",
        "def forward(X, W, b):\n",
        "    return X @ W + b\n",
        "\n",
        "def mse_loss(y_pred, y_true):\n",
        "    return np.mean((y_pred - y_true)**2)\n",
        "\n",
        "def l2_loss(W, lam):\n",
        "    return 0.5 * lam * np.sum(W * W)\n",
        "\n",
        "def compute_grads(X, y, y_pred, W, lam):\n",
        "    N = X.shape[0]\n",
        "\n",
        "    # gradient of MSE wrt predictions\n",
        "    dL_dy = (2/N) * (y_pred - y)\n",
        "\n",
        "    # gradients wrt parameters\n",
        "    dW = X.T @ dL_dy + lam * W   # L2 gradient added here\n",
        "    db = np.sum(dL_dy, axis=0)\n",
        "\n",
        "    return dW, db\n",
        "\n",
        "lr = 0.05\n",
        "lam = 0.1   # L2 strength\n",
        "\n",
        "for epoch in range(200):\n",
        "    y_pred = forward(X, W, b)\n",
        "\n",
        "    loss = mse_loss(y_pred, y) + l2_loss(W, lam)\n",
        "\n",
        "    dW, db = compute_grads(X, y, y_pred, W, lam)\n",
        "\n",
        "    # gradient descent update\n",
        "    W -= lr * dW\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch:3d} | Loss = {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9I7OGbc2lct",
        "outputId": "8d313043-f78b-4575-8ce9-f671112cb726"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Loss = 11.8049\n",
            "Epoch  20 | Loss = 0.9744\n",
            "Epoch  40 | Loss = 0.8899\n",
            "Epoch  60 | Loss = 0.8890\n",
            "Epoch  80 | Loss = 0.8890\n",
            "Epoch 100 | Loss = 0.8890\n",
            "Epoch 120 | Loss = 0.8890\n",
            "Epoch 140 | Loss = 0.8890\n",
            "Epoch 160 | Loss = 0.8890\n",
            "Epoch 180 | Loss = 0.8890\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}